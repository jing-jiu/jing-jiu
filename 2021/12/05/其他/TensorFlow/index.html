

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/jing-jiu/img/fluid.png">
  <link rel="icon" href="/jing-jiu/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Jing-Jiu">
  <meta name="keywords" content="">
  
    <meta name="description" content="TensorFlow相关">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow相关">
<meta property="og:url" content="https://jing-jiu.github.io/jing-jiu/2021/12/05/%E5%85%B6%E4%BB%96/TensorFlow/index.html">
<meta property="og:site_name" content="Jing-Jiu Blog">
<meta property="og:description" content="TensorFlow相关">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://jing-jiu.github.io/jing-jiu/img/avatar-star.jpg">
<meta property="article:published_time" content="2021-12-05T02:00:00.000Z">
<meta property="article:modified_time" content="2023-01-07T06:55:06.678Z">
<meta property="article:author" content="Jing-Jiu">
<meta property="article:tag" content="TensorFlow">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://jing-jiu.github.io/jing-jiu/img/avatar-star.jpg">
  
  
  
  <title>TensorFlow相关 - Jing-Jiu Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/jing-jiu/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/jing-jiu/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/jing-jiu/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"jing-jiu.github.io","root":"/jing-jiu/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/jing-jiu/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/jing-jiu/js/utils.js" ></script>
  <script  src="/jing-jiu/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/jing-jiu/">
      <strong>HOME</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/jing-jiu/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/jing-jiu/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/jing-jiu/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/jing-jiu/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/jing-jiu/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/jing-jiu/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="TensorFlow相关"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        Jing-Jiu
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2021-12-05 10:00" pubdate>
          2021年12月5日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          8.6k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          72 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">TensorFlow相关</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown">机器学习是对能通过经验自动改进的计算机算法的研究。用数据或以往经验，以优化计算机程序的性能标准。<br></code></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs markdown">人工神经网络：一种运算模型（输入输出的映射），由大量节点（神经元）互相连接构成。<br>神经网络 = 输入层（不用于计算神经网络层数） + 隐藏层（若干） + 输出层<br>神经元 = &#123;<br><span class="hljs-code">	权重:输入参数的权重,</span><br><span class="hljs-code">	偏置:针对差异做出的调节,</span><br><span class="hljs-code">	激活函数:用于添加一些非线性的变换</span><br><span class="hljs-code">&#125;</span><br><span class="hljs-code">输入乘上权重+偏置 经过激活函数的到输出</span><br></code></pre></td></tr></table></figure>

<p><img src="C:\Users\14828\AppData\Roaming\Typora\typora-user-images\image-20210725134218513.png" srcset="/jing-jiu/img/loading.gif" lazyload alt="image-20210725134218513"></p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs markdown">神经网络训练:给大量的输入（特征）输出（标签），算出神经网络所有神经元的权重，偏置，然后给定输入可以算出新的输出。<br>eg:给1000组相亲对象的数据（特征）以及满意程度（标签），训练完后，给定新的相亲对象数据就可以判定该数据的满意程度。<br></code></pre></td></tr></table></figure>

<h2 id="训练神经网络"><a href="#训练神经网络" class="headerlink" title="训练神经网络"></a>训练神经网络</h2><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-bullet">1.</span> 初始化<br>   随机生成一些权重和偏置。<br>   <br><span class="hljs-bullet">2.</span> 计算损失<br>   给定特征，计算出标签，得到与真实标签的误差。(损失函数)<br>   <br><span class="hljs-bullet">3.</span> 优化<br>   微调权重和和偏置，使损失降低。使用优化器（重复2，3使损失最小,<span class="hljs-strong">**从最后一层开始微调**</span>,梯度求导……）<br>   <br><span class="hljs-bullet">-</span> 前向传播<br>  将训练数据的特征送入网络，得到标签。<br>  <br><span class="hljs-bullet">-</span> [<span class="hljs-string">反向传播</span>](<span class="hljs-link">https://www.zhihu.com/question/24827633</span>)<br>  计算损失并优化。<br>  <br><span class="hljs-bullet">-</span> 计算损失(使用损失函数)<br></code></pre></td></tr></table></figure>

<h2 id="TensorFlowJS"><a href="#TensorFlowJS" class="headerlink" title="TensorFlowJS"></a>TensorFlowJS</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-comment">//Tensor:张量——向量和矩阵向更高维度的推广。（类似于多维数组）</span><br><span class="hljs-keyword">import</span> * <span class="hljs-keyword">as</span> tf <span class="hljs-keyword">from</span> <span class="hljs-string">&quot;@tensorflow/tfjs&quot;</span>;<br><span class="hljs-keyword">let</span> t0 = tf.<span class="hljs-title function_">tensor</span>([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]);<br>t0.<span class="hljs-title function_">print</span>();<br><span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(t0);<br><span class="hljs-keyword">let</span> t1 = tf.<span class="hljs-title function_">tensor</span>([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>]]);<br>t1.<span class="hljs-title function_">print</span>();<br><span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(t1);<br><span class="hljs-keyword">let</span> t2 = tf.<span class="hljs-title function_">tensor</span>([[[<span class="hljs-number">1</span>]]]);<br>t2.<span class="hljs-title function_">print</span>();<br><span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(t2);<br><span class="hljs-comment">// 传统for循环</span><br><span class="hljs-keyword">let</span> input = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>];<br><span class="hljs-keyword">let</span> w = [[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>],[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]];<br><span class="hljs-keyword">let</span> output = [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>];<br><span class="hljs-comment">// output = 所有指标的权重相乘之和</span><br><span class="hljs-comment">// 1*1+2*2+3*3+4*4,2*1+3*2+4*3+5*4……</span><br>w.<span class="hljs-title function_">forEach</span>(<span class="hljs-function">(<span class="hljs-params">i,index1</span>)=&gt;</span>&#123;<br>    input.<span class="hljs-title function_">forEach</span>(<span class="hljs-function">(<span class="hljs-params">j,index2</span>)=&gt;</span>&#123;<br>        output[index1] += i[index2]*j;<br>    &#125;)<br>&#125;)<br><span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(output);<br><span class="hljs-comment">// tensor 进行n层for循环  dot() 点积  矩阵之间的运算</span><br><span class="hljs-comment">// 会对dot内的矩阵进行转置</span><br>tf.<span class="hljs-title function_">tensor</span>(w).<span class="hljs-title function_">dot</span>(tf.<span class="hljs-title function_">tensor</span>(input)).<span class="hljs-title function_">print</span>();<br>tf.<span class="hljs-title function_">dot</span>(w,input);<br></code></pre></td></tr></table></figure>

<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown">线性回归:利用数理统计中回归分析，来确定两种或以上变量相互依赖的定量关系的一种统计分析。（身高体重预测，房价预测等）<br></code></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-bullet">1.</span> 初始化神经网络模型<br><span class="hljs-bullet">2.</span> 为神经网络模型添加层<br><span class="hljs-bullet">3.</span> 设计层的神经元个数和inputShape（输入形状） <br></code></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown">均方误差（MSE 损失函数之一）<br></code></pre></td></tr></table></figure>

<p><img src="C:\Users\14828\AppData\Roaming\Typora\typora-user-images\image-20210725135533341.png" srcset="/jing-jiu/img/loading.gif" lazyload alt="image-20210725135533341"></p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs markdown">随机梯度下降法（SGD 优化器之一）<br><span class="hljs-code">	SGD通常每次迭代一个样本 但在样本集数量过多的情况下会非常杂乱无章，因此在样本集数量非常多的情况下，使用小批量SGD。小批量 SGD 通常包含 10-1000 个随机选择的样本，可以减少 SGD 中的杂乱样本数量，但仍然比全批量更高效。</span><br><span class="hljs-code">	我们随机选取选取初始值w，使用 梯度x学习效率 来确定到下一个点的位置，重复上述操作，逐渐接近最低点。但是要注意学习效率的选取秒如果学习效率太大他会在最低点的两侧反复横跳，反之速度太慢会耗费过长的时间。</span><br><span class="hljs-code">[代码示例](https://developers.google.cn/machine-learning/crash-course/fitter/graph)</span><br></code></pre></td></tr></table></figure>

<p><img src="C:\Users\14828\AppData\Roaming\Typora\typora-user-images\image-20210725143611993.png" srcset="/jing-jiu/img/loading.gif" lazyload alt="image-20210725143611993"></p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-number">1.</span> 将训练数据转为<span class="hljs-title class_">Tensor</span><br><span class="hljs-keyword">let</span> inputs = tf.<span class="hljs-title function_">tensor</span>(xs);<br><span class="hljs-keyword">let</span> labels = tf.<span class="hljs-title function_">tensor</span>(ys);<br><span class="hljs-number">2.</span> 训练模型<br><span class="hljs-keyword">await</span> model.<span class="hljs-title function_">fit</span>(inputs,labels,&#123;<br>    <span class="hljs-attr">batchSize</span>:<span class="hljs-number">4</span>,<span class="hljs-comment">// </span><br>    <span class="hljs-attr">epochs</span>:<span class="hljs-number">100</span>,<br>    <span class="hljs-attr">callbacks</span>:tfvis.<span class="hljs-property">show</span>.<span class="hljs-title function_">fitCallbacks</span>(<br>        &#123;<span class="hljs-attr">name</span>:<span class="hljs-string">&#x27;训练过程&#x27;</span>&#125;,<br>        [<span class="hljs-string">&#x27;loss&#x27;</span>],<br>    )<br>&#125;)<br><span class="hljs-number">3.</span> 用tfvis可视化模型<br><span class="hljs-attr">callbacks</span>:tfvis.<span class="hljs-property">show</span>.<span class="hljs-title function_">fitCallbacks</span>(<br>    &#123;<span class="hljs-attr">name</span>:<span class="hljs-string">&#x27;训练过程&#x27;</span>&#125;,<br>    [<span class="hljs-string">&#x27;loss&#x27;</span>],<br>)<br></code></pre></td></tr></table></figure>

<h2 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-comment">//把大数量级特征转换成小数量级下，[0,1]或[-1,1]。</span><br><span class="hljs-keyword">let</span> inputMax = heights.<span class="hljs-title function_">sort</span>(<span class="hljs-function">(<span class="hljs-params">a,b</span>)=&gt;</span> b-a)[<span class="hljs-number">0</span>]<br><span class="hljs-keyword">let</span> inputMin = heights.<span class="hljs-title function_">sort</span>(<span class="hljs-function">(<span class="hljs-params">a,b</span>)=&gt;</span> b-a)[heights.<span class="hljs-property">length</span>-<span class="hljs-number">1</span>]<br><span class="hljs-keyword">let</span> labelMax = weights.<span class="hljs-title function_">sort</span>(<span class="hljs-function">(<span class="hljs-params">a,b</span>)=&gt;</span> b-a)[<span class="hljs-number">0</span>]<br><span class="hljs-keyword">let</span> labelMin = weights.<span class="hljs-title function_">sort</span>(<span class="hljs-function">(<span class="hljs-params">a,b</span>)=&gt;</span> b-a)[weights.<span class="hljs-property">length</span>-<span class="hljs-number">1</span>]<br><br><span class="hljs-keyword">let</span> inputs = tf.<span class="hljs-title function_">tensor</span>(height).<span class="hljs-title function_">sub</span>(inputMin).<span class="hljs-title function_">div</span>(inputMax-inputMin);<br><span class="hljs-keyword">let</span> labels = tf.<span class="hljs-title function_">tensor</span>(weight).<span class="hljs-title function_">sub</span>(labelMin).<span class="hljs-title function_">div</span>(labelMax-labelMin);<br><span class="hljs-comment">// sub 矩阵减 div 矩阵除 mul 矩阵乘 add 矩阵加</span><br><span class="hljs-comment">// 需要预测的输入数据也需要归一化</span><br><span class="hljs-keyword">let</span> output = model.<span class="hljs-title function_">predict</span>(tf.<span class="hljs-title function_">tensor</span>([<span class="hljs-number">175</span>]).<span class="hljs-title function_">sub</span>(inputMin).<span class="hljs-title function_">div</span>(inputMax-inputMin));<br></code></pre></td></tr></table></figure>

<h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-number">1.</span> 加载二分类数据集<br>tfvis.<span class="hljs-property">render</span>.<span class="hljs-title function_">scatterplot</span>(<br>	&#123; <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;逻辑回归训练集&#x27;</span> &#125;,<br>	&#123;<br>        <span class="hljs-attr">values</span>:[<br>        data.<span class="hljs-title function_">filter</span>(<span class="hljs-function"><span class="hljs-params">p</span>=&gt;</span>p.<span class="hljs-property">label</span> === <span class="hljs-number">1</span>),<br>        data.<span class="hljs-title function_">filter</span>(<span class="hljs-function"><span class="hljs-params">p</span>=&gt;</span>p.<span class="hljs-property">label</span> === <span class="hljs-number">0</span>)<br>		]<br>    &#125;,<br>);<br>显示两种点需要在values如上设置<br><span class="hljs-number">2.</span> 定义带有激活函数的单个神经元<br><span class="hljs-number">3.</span> 训练模型并预测<br></code></pre></td></tr></table></figure>

<h2 id="Box–Muller-Transform"><a href="#Box–Muller-Transform" class="headerlink" title="Box–Muller Transform"></a>Box–Muller Transform</h2><p>直角坐标下:<br><img src="C:\Users\14828\AppData\Roaming\Typora\typora-user-images\image-20210726165758067.png" srcset="/jing-jiu/img/loading.gif" lazyload alt="直角坐标"></p>
<p>极坐标下:</p>
<p><img src="C:\Users\14828\AppData\Roaming\Typora\typora-user-images\image-20210726170058111.png" srcset="/jing-jiu/img/loading.gif" lazyload alt="极坐标"></p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs markdown">[<span class="hljs-string">Box-Muller</span>](<span class="hljs-link">https://blog.csdn.net/weixin_41793877/article/details/84700875</span>)<br><span class="hljs-code">    do&#123;</span><br><span class="hljs-code">        // 生成-1~1之间的随机数  即极坐标下的某一点的坐标</span><br><span class="hljs-code">        v1 = 2*Math.random() - 1;</span><br><span class="hljs-code">        v2 = 2*Math.random() - 1;</span><br><span class="hljs-code">        s = v1 *v1 + v2*v2; //斜边的平方</span><br><span class="hljs-code">    &#125; while(s &gt; 1);</span><br><span class="hljs-code">    //如果s&gt;1就一直循环  当跳出循环则说明s&lt;1 确保s是在单位圆内</span><br><span class="hljs-code">Box-Muller公式 均值为0，方差为1 mean = 0 variance = 1</span><br><span class="hljs-code">	let result = Math.sqrt(-2 * Math.log(s) / s)* v1;</span><br><span class="hljs-code">	// 转成mean = mean variance为1的正态分布</span><br><span class="hljs-code">	return mean + Math.sqrt(variance) * result;</span><br></code></pre></td></tr></table></figure>

<h2 id="多层神经网络"><a href="#多层神经网络" class="headerlink" title="多层神经网络"></a>多层神经网络</h2><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown">XOR模型 使用多层神经网络配合激活函数进行模型预测<br></code></pre></td></tr></table></figure>

<p><img src="C:\Users\14828\AppData\Roaming\Typora\typora-user-images\image-20210726211555115.png" srcset="/jing-jiu/img/loading.gif" lazyload alt="image-20210726211555115"></p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs js">其实没啥 就是根据需要预测数据选择神经元的个数以及隐藏层的层数。选取合适的激活函数——relu/sigmoid……<br><span class="hljs-keyword">let</span> model = tf.<span class="hljs-title function_">sequential</span>();<br><span class="hljs-comment">// 隐藏层</span><br>model.<span class="hljs-title function_">add</span>(tf.<span class="hljs-property">layers</span>.<span class="hljs-title function_">dense</span>(&#123;<br>    <span class="hljs-attr">units</span>:<span class="hljs-number">4</span>,<span class="hljs-comment">// 四个神经元</span><br>    <span class="hljs-attr">inputShape</span>:[<span class="hljs-number">2</span>],<br>    <span class="hljs-attr">activation</span>:<span class="hljs-string">&quot;relu&quot;</span> <span class="hljs-comment">// 用于非线性的激活函数</span><br>&#125;))<br><span class="hljs-comment">// 输出层</span><br>model.<span class="hljs-title function_">add</span>(tf.<span class="hljs-property">layers</span>.<span class="hljs-title function_">dense</span>(&#123;<br>    <span class="hljs-attr">units</span>:<span class="hljs-number">1</span>,<br>    <span class="hljs-attr">activation</span>:<span class="hljs-string">&quot;sigmoid&quot;</span> <span class="hljs-comment">// 输出0-1之间的概率</span><br>&#125;))<br>model.<span class="hljs-title function_">compile</span>(&#123;<br>    <span class="hljs-attr">loss</span>:tf.<span class="hljs-property">losses</span>.<span class="hljs-property">logLoss</span>,<br>    <span class="hljs-attr">optimizer</span>:tf.<span class="hljs-property">train</span>.<span class="hljs-title function_">adam</span>(<span class="hljs-number">0.1</span>)<br>&#125;)<br></code></pre></td></tr></table></figure>

<h2 id="多分类任务"><a href="#多分类任务" class="headerlink" title="多分类任务"></a>多分类任务</h2><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs markdown">训练集（train）和验证集（test）<br><span class="hljs-code">	当我们使用神经网络进行模型构建的时候，我们使用训练集进行训练，而验证集则是从训练集中抽取的部分典型的样本，在我们训练模型时，如果对训练集训练得出的损失较小而验证集却损失非常大，则说明当前神经网络模型存在问题需要改进。</span><br></code></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs markdown">交叉熵损失函数<br><span class="hljs-code">	交叉熵能够衡量同一个随机变量中的两个不同概率分布的差异程度，在机器学习中就表示为真实概率分布与预测概率分布之间的差异。交叉熵的值越小，模型预测效果就越好。</span><br></code></pre></td></tr></table></figure>

<p><img src="C:\Users\14828\AppData\Roaming\Typora\typora-user-images\image-20210727115411350.png" srcset="/jing-jiu/img/loading.gif" lazyload alt="image-20210727115411350"></p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs markdown">重排数据<br><span class="hljs-code">	tf.util.shuffle(data);</span><br><span class="hljs-code">    随机排列提供给训练算法的样本的顺序。数据重排很重要，因为在训练期间，数据集通常会被拆分成较小的子集（称为批次），以用于训练模型。借助重排，每个批次可从分布的所有数据中获取各种数据。通过这样做，我们可以帮助模型：</span><br><span class="hljs-code">    -不学习纯粹依赖于数据输入顺序的东西</span><br><span class="hljs-code">    -对子组中的结构不敏感（例如，如果模型在训练的前半部分仅看到高马力汽车，可能会学习一种不适用于数据集其余部分的关系）。</span><br></code></pre></td></tr></table></figure>

<h2 id="欠拟合-x2F-过拟合"><a href="#欠拟合-x2F-过拟合" class="headerlink" title="欠拟合&#x2F;过拟合"></a>欠拟合&#x2F;过拟合</h2><p><img src="https://img-blog.csdn.net/20171102211431879?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMTgyNTQzODU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" srcset="/jing-jiu/img/loading.gif" lazyload alt="img"></p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs markdown">应对过拟合:<br>1.L1正则化<br><span class="hljs-code">	我们经常听到这样的话：“L1正则化是为了产生稀疏矩阵”，L1正则化的实现是在loss函数后面添加一个权重绝对值之和的项，该和再乘以一个系数，这个系数就是L1正则化的系数。这样做可以使得一些权重的值为0，降低了模型的复杂度，从而控制过拟合。</span><br><span class="hljs-code">2.L2正则化(权重衰减)</span><br><span class="hljs-code">kernelRegularizer:tf.regularizers.l2(&#123;l2:1&#125;)</span><br><span class="hljs-code">	L2正则化跟L1正则化的区别在于loss函数后加的是权重^2之和，该和再乘以一个系数，这个系数就是L2正则化的系数。这样做可以使得一些高次方项的权重为0，从而也降低了模型复杂度，控制了过拟合。以下是L2正则化的简单实现</span><br><span class="hljs-code">  	return (w**2).sum()/2</span><br><span class="hljs-code">3.早停法</span><br><span class="hljs-code">	早停是在训练过程中所采用的方法，在训练模型的时候观察验证集上的表现，如果验证集上的loss开始上升的时候，停止训练模型，从而阻止了模型进一步变得复杂</span><br><span class="hljs-code">4.丢弃法</span><br><span class="hljs-code">model.add(tf.layers.dropout(&#123; rate: 0.9 &#125;));</span><br><span class="hljs-code">	丢弃法一般用于全连接神经网络，它指的是一些神经元不继续传递其值，从而活动的神经元的数量变少，减少了模型的复杂度。</span><br></code></pre></td></tr></table></figure>

<h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown">与普通神经网络对比<br><span class="hljs-code">	普通的神经网络如果要提取一个图片的特征。以一个200x200的图片为例，需要提取200x200x3 = 12000 个特征。</span><br><span class="hljs-code">	卷积神经网络可以模拟人类的视觉处理流程，高效提取特征。</span><br></code></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs markdown">卷积层<br><span class="hljs-code">	卷积神经网络中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法最佳化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网路能从低级特征中迭代提取更复杂的特征。</span><br><span class="hljs-code">- 卷积运算</span><br><span class="hljs-code">	通过卷积核（filter/kernel）对图片特征进行提取。</span><br></code></pre></td></tr></table></figure>

<p><img src="C:\Users\14828\AppData\Roaming\Typora\typora-user-images\image-20210728121819215.png" srcset="/jing-jiu/img/loading.gif" lazyload alt="image-20210728121819215"></p>
<p><img src="C:\Users\14828\AppData\Roaming\Typora\typora-user-images\image-20210728121908287.png" srcset="/jing-jiu/img/loading.gif" lazyload alt="image-20210728121908287"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs mark">池化层<br>池化层夹在连续的卷积层中间， 用于压缩数据和参数的量，减小过拟合。简而言之，如果输入是图像的话，那么池化层的最主要作用就是压缩图像。<br>下采样层也叫池化层，其具体操作与卷积层的操作基本相同，只不过下采样的卷积核为只取对应位置的最大值、平均值等（最大池化、平均池化），即矩阵之间的运算规律不一样，并且不经过反向传播的修改。<br>池化层的作用:<br>1. invariance(不变性)，这种不变性包括translation(平移)，rotation(旋转)，scale(尺度)<br>2. 保留主要的特征同时减少参数(降维，效果类似PCA)和计算量，防止过拟合，提高模型泛化能力<br><br>A: 特征不变性，也就是我们在图像处理中经常提到的特征的尺度不变性，池化操作就是图像的resize，平时一张狗的图像被缩小了一倍我们还能认出这是一张狗的照片，这说明这张图像中仍保留着狗最重要的特征，我们一看就能判断图像中画的是一只狗，图像压缩时去掉的信息只是一些无关紧要的信息，而留下的信息则是具有尺度不变性的特征，是最能表达图像的特征。<br><br>B. 特征降维，我们知道一幅图像含有的信息是很大的，特征也很多，但是有些信息对于我们做图像任务时没有太多用途或者有重复，我们可以把这类冗余信息去除，把最重要的特征抽取出来，这也是池化操作的一大作用<br><br>(1) translation invariance：<br>这里举一个直观的例子(数字识别)，假设有一个16x16的图片，里面有个数字1，我们需要识别出来，这个数字1可能写的偏左一点(图1)，这个数字1可能偏右一点(图2)，图1到图2相当于向右平移了一个单位，但是图1和图2经过max pooling之后它们都变成了相同的8x8特征矩阵，主要的特征我们捕获到了，同时又将问题的规模从16x16降到了8x8，而且具有平移不变性的特点。图中的a（或b）表示，在原始图片中的这些a（或b）位置，最终都会映射到相同的位置。<br>(2) rotation invariance：<br>下图表示数字“0”的识别，第一张的“0”比较大，第二张的“0”进行了较小，相当于作了缩放，同样地，经过多次max pooling后具有相同的特征<br>池化层用的方法有Max pooling 和 average pooling，而实际用的较多的是Max pooling。这里就说一下Max pooling，其实思想非常简单。<br>对于每个2*2的窗口选出最大的数作为输出矩阵的相应元素的值，比如输入矩阵第一个2*2窗口中最大的数是6，那么输出矩阵的第一个元素就是6，如此类推。<br></code></pre></td></tr></table></figure>

<p><img src="https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430195106397-414671399.jpg" srcset="/jing-jiu/img/loading.gif" lazyload alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-a08dae108e328b5bb0ce81ed15267e09_hd.jpg" srcset="/jing-jiu/img/loading.gif" lazyload alt="img"></p>
<p><img src="https://img2018.cnblogs.com/blog/1093303/201901/1093303-20190120113539659-455066516.gif" srcset="/jing-jiu/img/loading.gif" lazyload alt="img"></p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown">全连接层 跟普通神经网络类似。<br></code></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown">对训练好的模型进行评估<br></code></pre></td></tr></table></figure>

<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-keyword">const</span> classNames = [<span class="hljs-string">&#x27;Zero&#x27;</span>, <span class="hljs-string">&#x27;One&#x27;</span>, <span class="hljs-string">&#x27;Two&#x27;</span>, <span class="hljs-string">&#x27;Three&#x27;</span>, <span class="hljs-string">&#x27;Four&#x27;</span>, <span class="hljs-string">&#x27;Five&#x27;</span>, <span class="hljs-string">&#x27;Six&#x27;</span>, <span class="hljs-string">&#x27;Seven&#x27;</span>, <span class="hljs-string">&#x27;Eight&#x27;</span>, <span class="hljs-string">&#x27;Nine&#x27;</span>];<br><span class="hljs-comment">//做出预测</span><br><span class="hljs-keyword">function</span> <span class="hljs-title function_">doPrediction</span>(<span class="hljs-params">model, data, testDataSize = <span class="hljs-number">500</span></span>) &#123;<br>    <span class="hljs-keyword">const</span> <span class="hljs-variable constant_">IMAGE_WIDTH</span> = <span class="hljs-number">28</span>;<br>    <span class="hljs-keyword">const</span> <span class="hljs-variable constant_">IMAGE_HEIGHT</span> = <span class="hljs-number">28</span>;<br>    <span class="hljs-keyword">const</span> testData = data.<span class="hljs-title function_">nextTestBatch</span>(testDataSize);<br>    <span class="hljs-keyword">const</span> testxs = testData.<span class="hljs-property">xs</span>.<span class="hljs-title function_">reshape</span>([testDataSize, <span class="hljs-variable constant_">IMAGE_WIDTH</span>, <span class="hljs-variable constant_">IMAGE_HEIGHT</span>, <span class="hljs-number">1</span>]);<br>    <span class="hljs-keyword">const</span> labels = testData.<span class="hljs-property">labels</span>.<span class="hljs-title function_">argMax</span>(-<span class="hljs-number">1</span>);<br>    <span class="hljs-keyword">const</span> preds = model.<span class="hljs-title function_">predict</span>(testxs).<span class="hljs-title function_">argMax</span>(-<span class="hljs-number">1</span>);<br>    testxs.<span class="hljs-title function_">dispose</span>();<br>    <span class="hljs-comment">//当使用WebGL后端时, tf.Tensor的内存必须以显式管理。这是因为WebGL不足以让tf.Tensor超出生命周期后内存被自动释放。您可以使用dispose方法或是tf.dispose方法用以释放tf.Tensor所占用的内存</span><br>    <span class="hljs-keyword">return</span> [preds, labels];<br>&#125;<br></code></pre></td></tr></table></figure>

<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-comment">//显示每个类的准确率</span><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span> <span class="hljs-title function_">showAccuracy</span>(<span class="hljs-params">model</span>) &#123;<br>    <span class="hljs-keyword">let</span> data = <span class="hljs-keyword">new</span> <span class="hljs-title class_">MnistData</span>();<br>    <span class="hljs-keyword">await</span> data.<span class="hljs-title function_">load</span>();<br>    <span class="hljs-keyword">const</span> [preds, labels] = <span class="hljs-title function_">doPrediction</span>(model, data);<br>    <span class="hljs-comment">//在预测和标签之间计算每个类别精度。标签和预测中的每个值都应对应于某些输出类 返回每个对象数组，每个对象都有一个准确性和每个类的计数属性</span><br>    <span class="hljs-keyword">const</span> classAccuracy = <span class="hljs-keyword">await</span> tfvis.<span class="hljs-property">metrics</span>.<span class="hljs-title function_">perClassAccuracy</span>(labels, preds);<br>    <span class="hljs-keyword">const</span> container = &#123; <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;Accuracy&#x27;</span>, <span class="hljs-attr">tab</span>: <span class="hljs-string">&#x27;Evaluation&#x27;</span> &#125;;<br>    <span class="hljs-comment">//为分类任务评估呈现每类精度表</span><br>    tfvis.<span class="hljs-property">show</span>.<span class="hljs-title function_">perClassAccuracy</span>(container, classAccuracy, classNames);<br>    labels.<span class="hljs-title function_">dispose</span>();<br>&#125;<br></code></pre></td></tr></table></figure>

<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-comment">//显示混淆矩阵</span><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span> <span class="hljs-title function_">showConfusion</span>(<span class="hljs-params">model</span>) &#123;<br>    <span class="hljs-keyword">let</span> data = <span class="hljs-keyword">new</span> <span class="hljs-title class_">MnistData</span>();<br>    <span class="hljs-keyword">await</span> data.<span class="hljs-title function_">load</span>();<br>    <span class="hljs-keyword">const</span> [preds, labels] = <span class="hljs-title function_">doPrediction</span>(model, data);<br>    <span class="hljs-keyword">const</span> confusionMatrix = <span class="hljs-keyword">await</span> tfvis.<span class="hljs-property">metrics</span>.<span class="hljs-title function_">confusionMatrix</span>(labels, preds);<br>    <span class="hljs-keyword">const</span> container = &#123; <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;Confusion Matrix&#x27;</span>, <span class="hljs-attr">tab</span>: <span class="hljs-string">&#x27;Evaluation&#x27;</span> &#125;;<br>    tfvis.<span class="hljs-property">render</span>.<span class="hljs-title function_">confusionMatrix</span>(container, &#123; <span class="hljs-attr">values</span>: confusionMatrix, <span class="hljs-attr">tickLabels</span>: classNames &#125;);<br>    labels.<span class="hljs-title function_">dispose</span>();<br>&#125;<br><span class="hljs-comment">//混淆矩阵与每个类的准确率相似，但会进一步细分以显示错误分类的模式。借助混淆矩阵，您可以了解模型是否对任何特定的类对感到困惑。</span><br></code></pre></td></tr></table></figure>

<h2 id="加载预训练模型"><a href="#加载预训练模型" class="headerlink" title="加载预训练模型"></a>加载预训练模型</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs js">在浏览器加载模型文件<br><span class="hljs-keyword">let</span> bin = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&#x27;bin&#x27;</span>);<br><span class="hljs-keyword">let</span> json = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&#x27;json&#x27;</span>);<br><span class="hljs-keyword">const</span> model = <span class="hljs-keyword">await</span> tf.<span class="hljs-title function_">loadLayersModel</span>(tf.<span class="hljs-property">io</span>.<span class="hljs-title function_">browserFiles</span>(<br>     [json.<span class="hljs-property">files</span>[<span class="hljs-number">0</span>], bin.<span class="hljs-property">files</span>[<span class="hljs-number">0</span>]]<br>));<br><br>后端直接加载模型<br><span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(<span class="hljs-string">&#x27;Loading mobilenet..&#x27;</span>);<br><span class="hljs-comment">// Load the model.</span><br><span class="hljs-keyword">let</span> net = <span class="hljs-keyword">await</span> mobilenet.<span class="hljs-title function_">load</span>();<br><span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(<span class="hljs-string">&#x27;Successfully loaded model&#x27;</span>);<br><span class="hljs-comment">// Make a prediction through the model on our image.</span><br><span class="hljs-keyword">const</span> imgEl = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&#x27;img&#x27;</span>);<br><span class="hljs-keyword">const</span> result = <span class="hljs-keyword">await</span> net.<span class="hljs-title function_">classify</span>(imgEl);<br>text.<span class="hljs-property">innerHTML</span> = result[<span class="hljs-number">0</span>].<span class="hljs-property">className</span>;<br><br><span class="hljs-keyword">let</span> imgFile = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&#x27;imgFile&#x27;</span>);<br><span class="hljs-keyword">let</span> img = <span class="hljs-keyword">await</span> <span class="hljs-title function_">file2img</span>(imgFile.<span class="hljs-property">files</span>[<span class="hljs-number">0</span>]);<br><span class="hljs-keyword">const</span> input = tf.<span class="hljs-title function_">tidy</span>(<span class="hljs-function">() =&gt;</span> &#123;<br>    <span class="hljs-keyword">return</span> tf.<span class="hljs-property">browser</span>.<span class="hljs-title function_">fromPixels</span>(img)<br>        .<span class="hljs-title function_">toFloat</span>()<br>        .<span class="hljs-title function_">sub</span>(<span class="hljs-number">255</span> / <span class="hljs-number">2</span>)<br>        .<span class="hljs-title function_">div</span>(<span class="hljs-number">255</span> / <span class="hljs-number">2</span>)<br>        .<span class="hljs-title function_">reshape</span>([<span class="hljs-number">1</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>, <span class="hljs-number">3</span>]);<br>&#125;);<br><span class="hljs-keyword">let</span> pred = (<span class="hljs-keyword">await</span> model).<span class="hljs-title function_">predict</span>(input)<br><span class="hljs-keyword">const</span> index = pred.<span class="hljs-title function_">argMax</span>(<span class="hljs-number">1</span>).<span class="hljs-title function_">dataSync</span>()[<span class="hljs-number">0</span>];<br><span class="hljs-keyword">let</span> text = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">&#x27;text&#x27;</span>);<br>text.<span class="hljs-property">innerHTML</span> = <span class="hljs-variable constant_">IMAGENET_CLASSES</span>[index];<br></code></pre></td></tr></table></figure>

<h2 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h2><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs markdown">1.加载模型并截断<br>2.构建神经网络<br>3，截断模型作为输入，神经网络作为输出<br><br><span class="hljs-strong">**在迁移学习完成之后，对模型进行使用（预测）时，其输入数据也是要经过截断模型进行处理，然后在将截断模型的输出作为输入传给迁移的模型。**</span><br></code></pre></td></tr></table></figure>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/jing-jiu/categories/%E5%85%B6%E4%BB%96/" class="category-chain-item">其他</a>
  
  
    <span>></span>
    
  <a href="/jing-jiu/categories/%E5%85%B6%E4%BB%96/TensorFlow/" class="category-chain-item">TensorFlow</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/jing-jiu/tags/TensorFlow/">#TensorFlow</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>TensorFlow相关</div>
      <div>https://jing-jiu.github.io/jing-jiu/2021/12/05/其他/TensorFlow/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Jing-Jiu</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2021年12月5日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/jing-jiu/2021/12/05/%E5%85%B6%E4%BB%96/WebRTC/" title="WebRTC相关">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">WebRTC相关</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/jing-jiu/2021/12/05/%E5%85%B6%E4%BB%96/RTP%20Media/" title="RTP Media">
                        <span class="hidden-mobile">RTP Media</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/jing-jiu/js/events.js" ></script>
<script  src="/jing-jiu/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/jing-jiu/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/jing-jiu/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/jing-jiu/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
